# PolyOCR: A Robust Multilingual OCR-to-Speech Pipeline with Language Detection and Translation ğŸ§ ğŸ—£

## Table of Contents ğŸ“š
- [Overview ğŸŒ](#overview-ğŸŒ)
- [Features ğŸŒŸ](#features-ğŸŒŸ)
- [System Architecture ğŸ—](#system-architecture-ğŸ—)
- [Key Components ğŸ§©](#key-components-ğŸ§©)
  - [1. Optical Character Recognition (OCR) ğŸ‘](#1-optical-character-recognition-ocr-ğŸ‘)
  - [2. Language Detection ğŸŒ](#2-language-detection-ğŸŒ)
  - [3. Translation Module ğŸŒ](#3-translation-module-ğŸŒ)
  - [4. Text-to-Speech (TTS) Synthesis ğŸ”Š](#4-text-to-speech-tts-synthesis-ğŸ”Š)
- [Accomplished Enhancements (Previously Future Work) âœ…](#accomplished-enhancements-previously-future-work-âœ…)
  - [Language-Specific Tuning and Script Adaptation âœ¨](#language-specific-tuning-and-script-adaptation-âœ¨)
  - [Enhanced UI/UX and Web Deployment ğŸ–¥](#enhanced-uiux-and-web-deployment-ğŸ–¥)
  - [Real-Time Camera Input Integration ğŸ“¸](#real-time-camera-input-integration-ğŸ“¸)
  - [Handwritten Text Support ğŸ“](#handwritten-text-support-ğŸ“)
  - [Model Switching Interface ğŸ›](#model-switching-interface-ğŸ›)
- [Installation and Usage ğŸ§°](#installation-and-usage-ğŸ§°)
  - [Prerequisites ğŸ”§](#prerequisites-ğŸ”§)
  - [Setup ğŸš€](#setup-ğŸš€)
  - [Running the Application â–¶](#running-the-application-â–¶)
- [Evaluation and Performance ğŸ“ˆ](#evaluation-and-performance-ğŸ“ˆ)
- [Team ğŸ¤](#team-ğŸ¤)
- [License ğŸ“„](#license-ğŸ“„)

## Overview ğŸŒ

*PolyOCR* is a robust and modular OCR-to-speech pipeline tailored to extract, understand, and vocalize text from images across multiple languages and scripts. It unifies:

- ğŸ“– *OCR* (via PaddleOCR)
- ğŸ§  *Language Detection* (via Langdetect)
- ğŸŒ *Translation* (via Googletrans)
- ğŸ”Š *Speech Synthesis* (via pyttsx3)

This end-to-end system bridges linguistic gaps, enabling document accessibility and cross-language communication in real-time.

## Features ğŸŒŸ

- ğŸ–¼ *Smart Image Preprocessing*: Automatic resizing, noise removal, and normalization for better OCR performance.
- ğŸŒ *Multilingual OCR*: Detects and reads over 80 languages using PaddleOCR.
- ğŸŒ *Accurate Language Identification*: Powered by Langdetect, supports 55+ languages.
- ğŸ§­ *Seamless Translation*: Converts text to English (or others) with NMT via Google Translate.
- ğŸ”‰ *Offline Text-to-Speech*: Converts any text into clear, offline-playable audio using pyttsx3.
- ğŸ“· *Live Camera Input*: Enables real-time text detection and translation from your webcam.
- âœ *Handwritten Text Support*: Recognizes cursive and historical writing styles.
- âš™ *Fully Modular Architecture*: Swap or modify components with ease.
- ğŸ–¥ *Intuitive Web UI*: Drag-and-drop upload, visual overlays, inline playback, and download options.
- ğŸ” *OCR Mode Selector*: Switch between General OCR, PP-Structure, or ChatOCR based on input.

## System Architecture ğŸ—

> *Input Image â†’ Preprocessing â†’ OCR â†’ Language Detection â†’ Translation â†’ TTS â†’ Output*

Each module is independently tunable and replaceable, enabling future flexibility and customization.

## Key Components ğŸ§©

### 1. Optical Character Recognition (OCR) ğŸ‘
- âœ… *PaddleOCR (PP-OCRv4)* ensures multilingual, CPU-efficient text extraction.
- ğŸ§± *DBNet*: Detects complex, curved, or rotated text regions.
- ğŸ”  *SVTR-LCNet*: Recognizes multilingual scripts, even under poor lighting or resolution.

### 2. Language Detection ğŸŒ
- ğŸ§  *Langdetect* uses Naive Bayes with character n-grams.
- Supports noisy, short input with 55+ languages.

### 3. Translation Module ğŸŒ
- ğŸ”„ *Googletrans API* for language translation with Neural Machine Translation.
- ğŸ§¹ Handles chunking, normalization, and code formatting for long inputs.

### 4. Text-to-Speech (TTS) Synthesis ğŸ”Š
- ğŸ’» *pyttsx3* for lightweight, platform-independent speech output.
- ğŸµ Exports audio in .mp3 or .wav format with offline capability.

## Accomplished Enhancements (Previously Future Work) âœ…

### Language-Specific Tuning and Script Adaptation âœ¨
- âœ Normalizes regional scripts for clarity.
- ğŸ§© Improves translation coherence.
- ğŸ§  Adds punctuation and pronunciation refinements.

### Enhanced UI/UX and Web Deployment ğŸ–¥
- ğŸŒ™ Dark & Light Modes
- ğŸ–± Drag-and-drop image upload
- ğŸ”² Bounding box overlays for OCR
- ğŸ§ Inline audio playback and download options

### Real-Time Camera Input Integration ğŸ“¸
- ğŸ‘ Read signboards, notes, and menus live
- âš™ Optimized for low-latency frame capture and streaming

### Handwritten Text Support ğŸ“
- ğŸ“– Recognizes cursive and unconstrained handwriting
- ğŸ› Supports old manuscripts, notes, and form parsing

### Model Switching Interface ğŸ›
- ğŸ” Select between OCR modes per document type
- ğŸ§¾ Better results for structured layouts and tables

## Installation and Usage ğŸ§°

### Prerequisites ğŸ”§
- Python 3.x
- Libraries: paddlepaddle, PaddleOCR, langdetect, googletrans, pyttsx3

### Setup ğŸš€
bash
git clone https://github.com/your-username/PolyOCR.git
cd PolyOCR
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate
pip install -r requirements.txt



Then open your browser at http://127.0.0.1:5000 and upload an image or use your webcam.

## Evaluation and Performance ğŸ“ˆ

| Metric                | Value                         |
|-----------------------|-------------------------------|
| OCR Accuracy (H-mean) | ~69.2% (on RRC dataset)       |
| Lang Detection        | High accuracy (major scripts) |
| Translation           | Manual fluency verification   |
| TTS Latency           | ~3.2 seconds (mid-range CPU)  |

## Team ğŸ¤

- Yogendra
- Rishabh
- Ayushi
- Shreya
- Sujith

## License ğŸ“„

Licensed under the *MIT License*. See [LICENSE](LICENSE) for full details.
