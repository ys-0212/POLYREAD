# PolyOCR: A Robust Multilingual OCR-to-Speech Pipeline with Language Detection and Translation ğŸ§ ğŸ—£

## Table of Contents ğŸ“š
- [Overview ğŸŒ](#overview-ğŸŒ)
- [Features ğŸŒŸ](#features-ğŸŒŸ)
- [System Architecture ğŸ—](#system-architecture-ğŸ—)
- [Key Components ğŸ§©](#key-components-ğŸ§©)
  - [1. Optical Character Recognition (OCR) ğŸ‘](#1-optical-character-recognition-ocr-ğŸ‘)
  - [2. Language Detection ğŸŒ](#2-language-detection-ğŸŒ)
  - [3. Translation Module ğŸŒ](#3-translation-module-ğŸŒ)
  - [4. Text-to-Speech (TTS) Synthesis ğŸ”Š](#4-text-to-speech-tts-synthesis-ğŸ”Š)
  - [Language-Specific Tuning and Script Adaptation âœ¨](#language-specific-tuning-and-script-adaptation-âœ¨)
  - [UI/UX and Web Deployment ğŸ–¥](#uiux-and-web-deployment-ğŸ–¥)
  - [Handwritten Text Support ğŸ“](#handwritten-text-support-ğŸ“)
- [Installation and Usage ğŸ§°](#installation-and-usage-ğŸ§°)
  - [Prerequisites ğŸ”§](#prerequisites-ğŸ”§)
  - [Setup ğŸš€](#setup-ğŸš€)
  - [Running the Application â–¶](#running-the-application-â–¶)
- [Team ğŸ¤](#team-ğŸ¤)
- [License ğŸ“„](#license-ğŸ“„)

## Overview ğŸŒ

*PolyOCR* is a robust and modular OCR-to-speech pipeline tailored to extract, understand, and vocalize text from images across multiple languages and scripts. It unifies:

- ğŸ“– *OCR* (via PaddleOCR)
- ğŸ§  *Language Detection* (via Langdetect)
- ğŸŒ *Translation* (via Googletrans)
- ğŸ”Š *Speech Synthesis* (via pyttsx3)

This end-to-end system bridges linguistic gaps, enabling document accessibility and cross-language communication in real-time.

## Features ğŸŒŸ

- ğŸ–¼ *Smart Image Preprocessing*: Automatic resizing, noise removal, and normalization for better OCR performance.
- ğŸŒ *Multilingual OCR*: Detects and reads 10 languages using PaddleOCR.
- ğŸŒ *Accurate Language Identification*: Powered by RoBERTa.
- ğŸ§­ *Seamless Translation*: Converts text to English (or others) with NMT via Google Translate.
- ğŸ”‰ *Offline Text-to-Speech*: Converts any text into clear, offline-playable audio using pyttsx3.
- âœ *Handwritten Text Support*: Recognizes cursive writing styles.
- âš™ *Fully Modular Architecture*: Swap or modify components with ease.
- ğŸ–¥ *Intuitive Web UI*: Drag-and-drop upload, visual overlays, inline playback, and download options.


## System Architecture ğŸ—

> *Input Image â†’ Preprocessing â†’ OCR_1 â†’ Language Detection â†’ OCR_2 â†’ Raw Text Output â†’ Translation â†’ TTS â†’ Audio Output*

Each module is independently tunable and replaceable, enabling future flexibility and customization.

## Key Components ğŸ§©

### 1. Optical Character Recognition (OCR) ğŸ‘
- âœ… *PaddleOCR (PP-OCRv4)*.

### 2. Language Detection ğŸŒ
- ğŸ§  *RoBERTo*.
  
### 3. Translation Module ğŸŒ
- ğŸ”„ *Googletrans API* 

### 4. Text-to-Speech (TTS) Synthesis ğŸ”Š
- ğŸ’» *pyttsx3* 



## UI/UX and Web Deployment ğŸ–¥
-  Dark & Light Modes
-  Drag-and-drop image upload
-  Bounding box overlays for OCR
-  Complete Raw Text Ouput Box
-  A line-by-line text output view with Hover-enabled boxes that reveal coordinate information 
-  A live translation module providing real-time results per selected segment
-  Inline audio playback and download options

## Installation and Usage ğŸ§°

### Prerequisites ğŸ”§
- Python 3.10

### Setup ğŸš€
```bash
git clone https://github.com/your-username/PolyOCR.git
cd PolyOCR
python -m venv venv
.\venv\Scripts\activate #windows
pip install -r requirements.txt
```

For CPU users
```bash
#install pytorch version 2.3.0
pip install torch==2.3.0+cpu torchvision==0.18.0+cpu torchaudio==2.3.0+cpu -f https://download.pytorch.org/whl/torch_stable.html
```

For GPU users
```bash
#install pytorch version 2.3.0 cu121
pip install torch==2.3.0 torchvision==0.18.0 torchaudio==2.3.0 --index-url https://download.pytorch.org/whl/cu121
```

Then open your browser at http://127.0.0.1:5000 and upload an image or use your webcam.



## Team ğŸ¤

- Yogendra
- Rishabh
- Ayushi
- Shreya
- Sujith

## License ğŸ“„

Licensed under the *MIT License*. See [LICENSE](LICENSE) for full details.
